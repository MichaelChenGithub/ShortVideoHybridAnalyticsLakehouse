✔ Checkpoint mismatch between spark ss, kafka, minio(iceberg) @started(26-01-30 19:09) @done(26-01-30 19:29) @lasted(20m59s)
    # issue: every time we restart Docker, the spark streaming job fails to resume from last checkpoint
    # root cause: Docker compose's volume only for MinIO, not for Spark and Kafka, and Iceberg REST(Catalog).
    # fix: remove volume for minio to start fresh every time. (Docker is not our focus here)
✔ Docker lakehouse-spark OOM @started(26-01-30 19:30) @done(26-01-30 20:09) @lasted(39m17s)
    # issue: spark job fails with OOM error after running for a while
    # root cause: We update the logic for gold layer increase shuffle pressure  (same order_id with same batch and we get the latest non-null total_amount)
    # fix: after diagnosing, we only got hundreds of row per batch, the window function should not cause OOM. Therefore, we make these changes in saprk-defaults.conf
        #   1. Decrease Memory Fraction (Make more space for Window Function)
        #   2. Set only 4 Spark Shuffle Partitions for prevent OOM in small cluster
        #   3. Limit JVM Heap size to avoid OOM 
✔ ivy_cache for spark in docker-compose.yml @started(26-01-30 20:10) @done(26-01-30 20:13) @lasted(3m53s)
    # issue: each time we build docker-compose, spark try to download all dependencies and somehow it fails. 
    # root cause: no maven/ivy cache volume for spark in docker-compose.yml
    # fix: add volume mapping for ivy cache in spark service in docker-compose.yml